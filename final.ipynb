{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "homedir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading company information...\n",
      "Loading all commodities...\n",
      "Loading all nace codes...\n",
      "Loading relevant codes...\n"
     ]
    }
   ],
   "source": [
    "# Load BEID's and company metadata\n",
    "print('Loading company information...')\n",
    "metadata = pd.read_excel(os.path.join(homedir,'metadata.xlsx'))\n",
    "\n",
    "# load commodity code / commodity name into dataframe commodities\n",
    "print('Loading all commodities...')\n",
    "commodities = pd.read_csv(os.path.join(homedir,'goederengroepen.txt'),sep=',', header=0, encoding='latin8')\n",
    "\n",
    "# load regkol code / regkol name into dataframe regkols\n",
    "print('Loading all nace codes...')\n",
    "regkols = pd.read_csv(os.path.join(homedir,'regkols.txt'),sep=',', header=0, encoding='latin8')\n",
    "\n",
    "# load RELEVANT regkol code / regkol name into dataframe regkols_rel\n",
    "print('Loading relevant codes...')\n",
    "regkols_rel = pd.read_csv(os.path.join(homedir,'regkols_relevant.txt'),sep=',', header=0, encoding='latin8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if commodity name: return commodity code\n",
    "# if commodity code: return commodity name\n",
    "def get_commodity(name_or_code):\n",
    "    if isinstance(name_or_code,int): \n",
    "        return commodities.loc[commodities['gg_code'] == name_or_code]['gg_info'].values[0]\n",
    "    return commodities.loc[commodities['gg_info'] == name_or_code]['gg_code'].values[0]\n",
    "\n",
    "# if regkol name: return regkol code\n",
    "# if regkol code: return regkol name\n",
    "def get_regkol(name_or_code):\n",
    "    if isinstance(name_or_code,int): \n",
    "        return regkols.loc[regkols['rk_code'] == name_or_code]['rk_info'].values[0]\n",
    "    return regkols.loc[regkols['rk_info'] == name_or_code]['rk_code'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if supply = 'supply': return producers of commodity commodity\n",
    "# if supply = 'use':    return consucers of commodity commodity\n",
    "def get_companies(supply,commodity):\n",
    "    commodity = str(commodity) + '.csv'\n",
    "    path = os.path.join(homedir,supply,commodity)\n",
    "    companies = pd.read_csv(path,sep=';').rename(columns={'id':'BEID','nace':'nace_code'})\n",
    "    irrelevant_columns = ['lon','lat','score','indegree','outdegree']\n",
    "    for column in irrelevant_columns:\n",
    "        if column not in companies.columns:\n",
    "            irrelevant_columns.remove(column)\n",
    "    companies = companies.drop(irrelevant_columns,axis=1)\n",
    "    if companies['volume'].dtype == object:\n",
    "        companies['volume'] = companies['volume'].str.split(',').str[0]\n",
    "    companies['volume'] = companies['volume'].astype('int64')\n",
    "    companies['rel_volume'] = companies['volume']/companies['volume'].sum()*100\n",
    "    companies['commodity_code'] = commodity.split('.')[0]\n",
    "    companies['supply/use'] = supply\n",
    "    return companies.sort_values(['volume'],ascending=False)\n",
    "\n",
    "def add_metadata(df):\n",
    "    return pd.merge(df,metadata,how='left',on='BEID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_chain(commodities):\n",
    "    value_chain = pd.DataFrame()\n",
    "    for commodity in commodities:\n",
    "        if isinstance(commodity,str):\n",
    "            commodity = get_commodity(commodity)\n",
    "        for role in ['supply','use']:\n",
    "            value_chain = pd.concat([value_chain,get_companies(role,commodity)])\n",
    "    value_chain['commodity_code'] = value_chain['commodity_code'].astype(int)\n",
    "    value_chain['supply/use'] = value_chain['supply/use'].astype(str)\n",
    "    return value_chain\n",
    "\n",
    "def calculate_statistics(value_chain):\n",
    "    # split by commodity, supply/use and industry\n",
    "    niches = value_chain.groupby(['commodity_code','supply/use','nace_code'],sort=False)\n",
    "    # for all fragments: count number of companies, sum of relative volume and absolute volume\n",
    "    all_stats = niches['BEID'].count().reset_index()\n",
    "    all_stats['rel_volume'] = niches['rel_volume'].sum().reset_index()['rel_volume']\n",
    "    all_stats['abs_volume'] = niches['volume'].sum().reset_index()['volume']\n",
    "    # add commodity totals\n",
    "    commodity_totals = value_chain.groupby(['commodity_code','supply/use'])['volume'].sum().reset_index()\n",
    "    all_stats['commodity_title'] = all_stats['commodity_code'].apply(lambda x: get_commodity(int(x)))\n",
    "    all_stats['nace_title'] = all_stats['nace_code'].apply(lambda x: get_regkol(int(x)))\n",
    "    all_stats = pd.merge(all_stats, commodity_totals, how='left')\n",
    "    all_stats = all_stats.reindex(columns = ['commodity_title','supply/use','nace_title','rel_volume','abs_volume','BEID','volume'])\n",
    "    return all_stats.groupby(['commodity_title','supply/use','nace_title']).first()\n",
    "\n",
    "def filter_naces(relevant_nodes):\n",
    "    relevant_naces = regkols_rel['rk_code'].tolist()\n",
    "    return relevant_nodes[relevant_nodes['nace_code'].isin(relevant_naces)]\n",
    "\n",
    "\n",
    "def original_commodity_volumes(all_nodes):\n",
    "    return all_nodes.groupby(['commodity_code','supply/use'])['volume'].sum() \n",
    "\n",
    "def select_q_victims(candidates,quantity):\n",
    "    direct_victims = pd.DataFrame(columns=candidates.columns)\n",
    "    for i in range(0,quantity):\n",
    "        target_node = candidates.sample()\n",
    "        candidates = candidates.drop(target_node.index)\n",
    "        direct_victims = pd.concat([direct_victims,target_node])\n",
    "    return direct_victims\n",
    "\n",
    "def simulate_victims(commodity_seq,deletions):\n",
    "    all_nodes = value_chain(commodity_seq)\n",
    "    original_volumes = original_commodity_volumes(all_nodes)\n",
    "    nodes_filtered = filter_naces(all_nodes)\n",
    "    commodity_code = get_commodity(commodity_seq[0])\n",
    "    candidates = all_nodes[(all_nodes['commodity_code'] == commodity_code) & (all_nodes['supply/use'] == 'supply')]\n",
    "    direct_victims = select_q_victims(candidates,deletions)    \n",
    "    return direct_victims\n",
    "\n",
    "\n",
    "def descriptive_statistics(commodity_seq):\n",
    "    all_nodes = value_chain(commodity_seq)\n",
    "    filtered_nodes = filter_naces(all_nodes)\n",
    "    commodity_totals = filtered_nodes.groupby(['commodity_code','supply/use'])['volume'].sum().reset_index()\n",
    "\n",
    "    sur = []\n",
    "    for commodity_text in commodity_seq:\n",
    "        commodity = get_commodity(commodity_text)\n",
    "        print(commodity)\n",
    "        supply_use = commodity_totals.loc[commodity_totals['commodity_code'] == commodity]['volume'].tolist()\n",
    "        print(supply_use)\n",
    "        sur.append(supply_use[1]/supply_use[0]*100)\n",
    "    print(sur)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_volumes(nodes):\n",
    "    return nodes.groupby(['commodity_code','supply/use'])['volume'].sum().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "def check_deficit(stats, commodity_seq):\n",
    "    for commodity in commodity_seq:\n",
    "        layer = stats[stats['commodity_code']==get_commodity(commodity)]\n",
    "        if (layer['actual_deficit']>0).any():\n",
    "            return commodity, layer['actual_deficit'][0]\n",
    "    return None, 0\n",
    "\n",
    "def find_shortage_victim(nodes, commodity, volume):\n",
    "    candidates = nodes[nodes['commodity_code'] == get_commodity(commodity)]\n",
    "    producing_candidates = candidates[candidates['supply/use'] == 'use']\n",
    "    large_producing_candidates = producing_candidates[producing_candidates['volume'] > volume]\n",
    "    return large_producing_candidates.loc[large_producing_candidates['volume'].idxmin()]\n",
    "\n",
    "def highest_producer(nodes):\n",
    "    return nodes.loc[nodes['volume'].idxmax()]\n",
    "\n",
    "\n",
    "def run_experiment(commodity_seq, n_removed_nodes):\n",
    "    # get nodes, filter, calculate initial volumes\n",
    "    all_nodes = value_chain(commodity_seq)\n",
    "    filtered_nodes = filter_naces(all_nodes)\n",
    "    initial_volumes = get_volumes(filtered_nodes)\n",
    "    print(initial_volumes)\n",
    "    \n",
    "    history = pd.DataFrame()\n",
    "    targeted_nodes = pd.DataFrame()\n",
    "    victimized_nodes = pd.DataFrame()\n",
    "    \n",
    "    for i in range(1, n_removed_nodes+1):\n",
    "\n",
    "        # get producers of initial resource\n",
    "        companies_r = filtered_nodes[filtered_nodes['commodity_code'] == get_commodity(commodity_seq[0])]\n",
    "        producers_r = companies_r[companies_r['supply/use'] == 'supply']\n",
    "\n",
    "        # get target node\n",
    "        targeted_node = producers_r.loc[producers_r['volume'].idxmax()]\n",
    "        filtered_nodes = filtered_nodes[filtered_nodes.BEID != targeted_node.BEID]\n",
    "        targeted_nodes = pd.concat([targeted_nodes,targeted_node])\n",
    "\n",
    "        # calculate current volumes\n",
    "        stats = get_statistics(filtered_nodes, initial_volumes, i)\n",
    "        \n",
    "        stats['relative_deficit']  = stats['actual_deficit']/stats['initial_volumes'] \n",
    "        \n",
    "        # check for deficits\n",
    "        problem_commodity, volume_deficit = check_deficit(stats, commodity_seq)\n",
    "\n",
    "        while volume_deficit > 0:\n",
    "            print('whiehoe hoeh deficit')\n",
    "            large_consumers = filtered_nodes[filtered_nodes['commodity_code']== get_commodity(problem_commodity)]\n",
    "            large_consumers = large_consumers[large_consumers['supply/use'] == 'use']\n",
    "            print(large_consumers.head())\n",
    "            # consumers that can fix the deficit by themselves \n",
    "            large_enough_consumers = large_consumers[large_consumers['volume'] > volume_deficit]\n",
    "\n",
    "            if large_enough_consumers.empty:\n",
    "                victim_node = large_consumers.loc[large_consumers['volume'].idxmax()]\n",
    "            else:\n",
    "                victim_node = large_enough_consumers.loc[large_enough_consumers['volume'].idxmin()]\n",
    "            victimized_nodes = pd.concat([victimized_nodes,victim_node])\n",
    "            filtered_nodes = filtered_nodes[filtered_nodes.BEID != victim_node.BEID]\n",
    "            problem_commodity, volume_deficit = check_deficit(stats, commodity_seq)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         while (stats['actual_deficit']>0).any():\n",
    "#             shortage = check_deficit(stats, commodity_seq)\n",
    "#             print(shortage)\n",
    "#             print(stats)\n",
    "#             if shortage != None:\n",
    "#                 volume = stats['commodity_code'==get_commodity(shortage)]['volume']\n",
    "#                 print(volume)\n",
    "#                 victim = find_shortage_victim(filtered_nodes,shortage,volume)\n",
    "#                 filtered_nodes = filtered_nodes.drop(victim)\n",
    "        history = history.append(stats)\n",
    "    return history\n",
    "\n",
    "def get_statistics(nodes, initial_volumes, i):\n",
    "    # calculate current volumes\n",
    "    current_volumes = get_volumes(nodes)\n",
    "    delta_volumes = (initial_volumes['volume'] - current_volumes['volume'])\n",
    "    stats = initial_volumes.rename(columns={'volume':'initial_volume'})\n",
    "    stats['current_volume'] = current_volumes['volume']\n",
    "    stats['delta_volume'] = delta_volumes\n",
    "\n",
    "        # calculate upscaling capacity of producers\n",
    "    stats['max_upscaling'] = np.where(stats['supply/use'] == 'supply', stats['current_volume']*0.2, 0)\n",
    "    stats['deficit_no_upscaling'] = np.where(stats['supply/use'] == 'use', pd.rolling_apply(stats['delta_volume'], 2, lambda x: x[0] - x[1]),0)\n",
    "\n",
    "    stats.loc[:,'deficit_no_upscaling'] = stats.deficit_no_upscaling.shift(-1).fillna(0)\n",
    "    stats['actual_deficit'] = stats['deficit_no_upscaling'] - stats['max_upscaling']\n",
    "        \n",
    "    stats['nodes_removed'] = i\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_experiment(['Aardgas','Vloeib.PropaanButaan','Polypropyleen'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
